{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection, svm, cross_validation\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data from Quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = quandl.get(\"WIKI/GOOGL\")\n",
    "#print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking relevent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]\n",
    "data['HL_Percentage'] = (data['Adj. High'] - data['Adj. Close']) / data['Adj. Close'] * 100\n",
    "data['Percentage_change'] = (data['Adj. Close'] - data['Adj. Open']) / data['Adj. Open'] * 100\n",
    "data = data[['Adj. Close','HL_Percentage','Percentage_change','Adj. Volume']]\n",
    "#print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting some value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcast_col = 'Adj. Close'\n",
    "\n",
    "data.fillna(-999999,inplace=True) # What this does is that it replaces all the NA with -999999\n",
    "# We replace this NA data with some value(an outlier) becauese we cannot work with NA value in ML\n",
    "'''We can also get rid of the data but we choose not to because we donot want to loose data in ML, so instead we replace\n",
    "   it with a outlier'''\n",
    "\n",
    "forecast_out = int(math.ceil(0.01*len(data)))\n",
    "#this is just to pridict the value based on stocks from 1- days back\n",
    "#print \"The length of the dataframe is: \"+str(len(data.index))\n",
    "\n",
    "data['lable'] = data[forcast_col].shift(-forecast_out)\n",
    "#we are basically moving it up\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794848134194978\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data.drop('lable',1))\n",
    "y = np.array(data['lable'])\n",
    "x = preprocessing.scale(x) #this normalizes the data\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(x,y,test_size = .2) #.2 means that we want 20% of the data\n",
    "'''\n",
    "    Eg,\n",
    "    X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "    \n",
    "    print (X)\n",
    "    array([[0, 1],\n",
    "           [2, 3],\n",
    "           [4, 5],\n",
    "           [6, 7],\n",
    "           [8, 9]])\n",
    "    \n",
    "    print(list(y))\n",
    "    [0, 1, 2, 3, 4]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    print(X_train)\n",
    "    array([[4, 5],\n",
    "           [0, 1],\n",
    "           [6, 7]])\n",
    "    \n",
    "    print(y_train)\n",
    "    [2, 0, 3]\n",
    "    \n",
    "    print(X_test)\n",
    "    array([[2, 3],\n",
    "           [8, 9]])\n",
    "    \n",
    "    print(y_test)\n",
    "    [1, 4]\n",
    "    \n",
    "    train_test_split(y, shuffle=False)\n",
    "    [[0, 1, 2], [3, 4]]\n",
    "'''\n",
    "clf = LinearRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "accuracy = clf.score(x_test,y_test)\n",
    "print (accuracy) #this is the accuracy i.e 91% or 92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To chage the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7937822215469545\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR() #stands for support vector regression\n",
    "#we have something called kernel which by default is linear but we can change it\n",
    "clf.fit(x_train,y_train)\n",
    "accuracy = clf.score(x_test,y_test)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To change to polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6606383271538057\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR(kernel = 'poly') #stands for support vector regression\n",
    "#we have something called kernel which by default is linear but we can change it\n",
    "clf.fit(x_train,y_train)\n",
    "accuracy = clf.score(x_test,y_test)\n",
    "print (accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
